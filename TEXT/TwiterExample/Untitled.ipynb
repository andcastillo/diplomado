{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy %f\n",
      " 0.9691569568197396\n",
      "Confusion Matrix\n",
      "  |    0    1 |\n",
      "--+-----------+\n",
      "0 |<1239>  38 |\n",
      "1 |   52<1589>|\n",
      "--+-----------+\n",
      "(row = reference; col = test)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "@package sentiment\n",
    "Twitter sentiment analysis.\n",
    "\n",
    "This code performs sentiment analysis on Tweets.\n",
    "\n",
    "A custom feature extractor looks for key words and emoticons.  These are fed in\n",
    "to a naive Bayes classifier to assign a label of 'positive', 'negative', or\n",
    "'neutral'.  Optionally, a principle components transform (PCT) is used to lessen\n",
    "the influence of covariant features.\n",
    "\n",
    "pip3 install -U nltk\n",
    "pip3 install MDP\n",
    "\n",
    "\"\"\"\n",
    "import csv, random\n",
    "import nltk\n",
    "import tweet_features, tweet_pca\n",
    "\n",
    "\n",
    "# read all tweets and labels\n",
    "fp = open( '../datasets/train.txt', 'r' )\n",
    "reader = csv.reader( fp, delimiter='\\t', quotechar='\"', escapechar='\\\\' )\n",
    "tweets = []\n",
    "for row in reader:\n",
    "    tweets.append( [row[1], row[0]] );\n",
    "\n",
    "\n",
    "# treat neutral and irrelevant the same\n",
    "for t in tweets:\n",
    "    if t[1] == 'irrelevant':\n",
    "        t[1] = 'neutral'\n",
    "\n",
    "\n",
    "# split in to training and test sets\n",
    "random.shuffle( tweets );\n",
    "\n",
    "fvecs = [(tweet_features.make_tweet_dict(t),s) for (t,s) in tweets]\n",
    "v_train = fvecs[:4000]\n",
    "v_test  = fvecs[4000:]\n",
    "\n",
    "\n",
    "# dump tweets which our feature selector found nothing\n",
    "#for i in range(0,len(tweets)):\n",
    "#    if tweet_features.is_zero_dict( fvecs[i][0] ):\n",
    "#        print tweets[i][1] + ': ' + tweets[i][0]\n",
    "\n",
    "\n",
    "# apply PCA reduction\n",
    "#(v_train, v_test) = \\\n",
    "#        tweet_pca.tweet_pca_reduce( v_train, v_test, output_dim=1.0 )\n",
    "\n",
    "\n",
    "# train classifier\n",
    "classifier = nltk.NaiveBayesClassifier.train(v_train);\n",
    "#classifier = nltk.classify.maxent.train_maxent_classifier_with_gis(v_train);\n",
    "\n",
    "\n",
    "# classify and dump results for interpretation\n",
    "print ('\\nAccuracy %f\\n', nltk.classify.accuracy(classifier, v_test))\n",
    "#print classifier.show_most_informative_features(200)\n",
    "\n",
    "\n",
    "# build confusion matrix over test set\n",
    "test_truth   = [s for (t,s) in v_test]\n",
    "test_predict = [classifier.classify(t) for (t,s) in v_test]\n",
    "\n",
    "print('Confusion Matrix')\n",
    "print(nltk.ConfusionMatrix( test_truth, test_predict ))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clasifiquemos un nuevo tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.classify(tweet_features.make_tweet_dict(\"Obama is an asshole\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
