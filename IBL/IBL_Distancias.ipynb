{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instance Based Learning(IBL)\n",
    "## Aprendizaje basado en Instancias\n",
    "\n",
    "**Universidad del Valle**\n",
    "\n",
    "Diplomado en Ciencia de Datos\n",
    "\n",
    "Docente: _Andres Mauricio Castillo_ \n",
    "\n",
    "El aprendizaje basado en instancias, a diferencia de otros algoritmos, no involucra la construcción de una generalización abstracta explicita, sino que clasifica nuevas instancias basado en comparaciones directas y similitudes con respectro a instancias de entrenamiento conocidas.\n",
    "\n",
    "* El entranamiento puede ser muy fácil, solo debe memorizar las instancias de entrenamiento\n",
    "* La evaluación puede ser muy costosa, ya que requiere una comparación exahustiva con todas las instancias de entrenamiento conocidas.\n",
    "* Este tipo de algoritmos son conocidos también cómo:\n",
    "  * Basados en casos (Case-based)\n",
    "  * Basado en ejemplos (Examplar-based)\n",
    "  * Vecinos más cercanos (Nearest Neighbor)\n",
    "  * Basados en memoria (Memory-based)\n",
    "  * Aprendizaje perezoso(Lazy Learning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Métricas de Similitud/Distancia\n",
    "\n",
    "* Los métoos basados en instancias asumen una función para determinar la similitud o distancia entre cualquier par de instancias.\n",
    "* Para vectores de características continuos, la distancia Euclidiana es usada generalmente:\n",
    "\n",
    "   $$d(x, y) = \\sqrt { \\sum_{p=1}^{n} (x_p - y_p )^2 }$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Para características discretas, la distancia entre ellos es 0 si son iguales y 1 si son diferentes(Por ejemplo la distancia de Hamming para vectores de bits)\n",
    "* Para compensar las diferencias de escala entre atributos, se deben escalar todos los atributos continuos al intervalo [0, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Otras medidas de distancia\n",
    "\n",
    "* Distancia de Mahalanobits\n",
    "  - Métrica invariante a la escala que normaliza con la varianza\n",
    "  $$m(x, y)=\\sqrt {(x - y) V^{-1}(x - y)^T}$$\n",
    "* Similitud Coseno\n",
    "  - Coseno del ángulo entre 2 vectores\n",
    "  - Usada en texto y otros datos de alta dimensionalidad\n",
    "* Correlación de Pearson\n",
    "  -Coeficiente de correlación estadística estándar.\n",
    "  -Usada en datos bioinformáticos\n",
    "  $$cos(x,y)= \\frac{x*y}{\\|{x}\\| * \\|y\\|}$$\n",
    "* Distancia de edición\n",
    "  -Usada para medir la distancia entre cadenas de logintud variable\n",
    "  -Usada en texto y bioinformática"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Euclidean  6.40312423743\n",
      "Hamming  2\n",
      "Mahalanobits  8.831760866327864\n",
      "Cosine  0.707106781187\n"
     ]
    }
   ],
   "source": [
    "import numpy  as np\n",
    "import math\n",
    "from numpy import linalg as LA\n",
    "\n",
    "\n",
    "#Euclidean distance\n",
    "x = np.array([1, 10])\n",
    "y = np.array([-3, 5])\n",
    "euclidean = LA.norm(x - y) \n",
    "print(\"Euclidean \", euclidean)\n",
    "\n",
    "# Hamming distance\n",
    "xb = np.array([1, 0, 1, 2, 3 ])\n",
    "yb = np.array([1, 0, 0, 2, 1 ])\n",
    "\n",
    "hamming = np.count_nonzero(xb != yb)\n",
    "print(\"Hamming \", hamming)\n",
    "\n",
    "# Mahalanobits distance\n",
    "data = np.transpose(np.array([[3, 2, 9], [7, 11, 1], [3, 3, 7], [2, 1, 6]]))\n",
    "x = np.array([1, 10, 0]);\n",
    "y = np.array([-3, 5, 0]);\n",
    "VI = np.linalg.inv(np.cov(data));\n",
    "maha = math.sqrt(np.dot(np.dot([x - y], VI), np.transpose([x - y])))\n",
    "print(\"Mahalanobits \", maha)\n",
    "\n",
    "#Similitud coseno\n",
    "xc = np.array([1, 0])\n",
    "yc = np.array([1, 1])\n",
    "#yc = np.array([0, 1])\n",
    "cos = np.dot(xc, yc) / math.sqrt((np.dot(xc, xc) *  np.dot(yc, yc)))\n",
    "print(\"Cosine \", cos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
